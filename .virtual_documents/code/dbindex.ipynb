


from datasets import load_dataset
import spacy as sp
import random
import en_core_web_lg
import pandas as pd


nlp = en_core_web_lg.load()


dataset = load_dataset("ccdv/govreport-summarization")
dataset


dataset.set_format(type='pandas')
targetdset = dataset['train'][1:]
targetdset.drop(['summary'], axis=1)





offensivedataset = load_dataset("henryscheible/implicit_bias")


offensivedataset.set_format(type='pandas')
compdataset = offensivedataset['train'][1:]
compdataset.drop(['category', 'label'], axis = 1)


def dbindex(target, comparison):
    #Pick a random entry from the comparison dataset.
    index = random.randrange(0, comparison.size, 1)

    #Find that entry.
    comparisonEntry = comparison['sentence'][index]

    #Vectoritze entry.
    vectorizedComparisonEntry = nlp(comparisonEntry)

    #initialitize total cosine similarity
    tcs = 0

    #Go through each target entry
    for entry in target.report:
        
        #Find similariity between each target and the comparison entry
        vecEntry = nlp(entry)
        tcs += vecEntry.similarity(vectorizedComparisonEntry)

    #Raise to inverse power of size
    dbi = tcs**(1/len(target))
    return dbi


target = pd.DataFrame(["grey", "grey"])
target.columns = ['report']
comparison = pd.DataFrame(['white', "red", "orange"])
comparison.columns = ['sentence']


dbindex(target, comparison)
