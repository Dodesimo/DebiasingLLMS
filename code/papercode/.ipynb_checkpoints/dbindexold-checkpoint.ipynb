{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e9b59a1-d769-4726-b5f4-ff7aa382322c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "<h1>db-index, new way to measure dataset bias</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "044a9cbd-92ab-400b-80dd-17c89a291b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import spacy as sp\n",
    "import random\n",
    "import en_core_web_lg\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9bf2e81-02d6-4e47-a368-0201793c244a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = en_core_web_lg.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad14cdf1-83bd-434c-8663-f53a0bc762d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['report', 'summary'],\n",
       "        num_rows: 17517\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['report', 'summary'],\n",
       "        num_rows: 973\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['report', 'summary'],\n",
       "        num_rows: 973\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"ccdv/govreport-summarization\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6308c8d-a2ab-4a80-a38d-da0f0e8d7e0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Most income derived from private sector busine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>There are some similarities in how Medicare pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IRS’s mission is to provide America’s taxpayer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In 1991, we reported that, historically, INS l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>While TCE and perchlorate are both DOD-classif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17511</th>\n",
       "      <td>Some Members of Congress have expressed intere...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17512</th>\n",
       "      <td>Since November 1986, the Commemorative Works A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17513</th>\n",
       "      <td>On May 27, 2015, the Army Corps of Engineers (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17514</th>\n",
       "      <td>Section 1512 applies to the obstruction of fed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17515</th>\n",
       "      <td>Medicaid is a federal-state entitlement progra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17516 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  report\n",
       "0      Most income derived from private sector busine...\n",
       "1      There are some similarities in how Medicare pa...\n",
       "2      IRS’s mission is to provide America’s taxpayer...\n",
       "3      In 1991, we reported that, historically, INS l...\n",
       "4      While TCE and perchlorate are both DOD-classif...\n",
       "...                                                  ...\n",
       "17511  Some Members of Congress have expressed intere...\n",
       "17512  Since November 1986, the Commemorative Works A...\n",
       "17513  On May 27, 2015, the Army Corps of Engineers (...\n",
       "17514  Section 1512 applies to the obstruction of fed...\n",
       "17515  Medicaid is a federal-state entitlement progra...\n",
       "\n",
       "[17516 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.set_format(type='pandas')\n",
    "targetdset = dataset['train'][1:]\n",
    "targetdset.drop(['summary'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79be650-b1df-46e8-adbb-b0f4b6b7ef2f",
   "metadata": {},
   "source": [
    "Dataset sanitized. Let's get a sample dataset of offensive language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95a9d6c4-1a6f-4a11-8a45-bbb857e7d2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "offensivedataset = load_dataset(\"henryscheible/implicit_bias\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e04a8a6-46c0-4b5d-8629-243234b42a8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>They are Asians. I don't want to invite too ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>They are Queer. Why do all gay men have to be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>They are OldPeople. All Middle Easterners are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>They are Females. She's always so put together...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>They are Christans. I don't understand how you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>They are MiddleEastern. I saw a group of Middl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>They are Asians. Oh, my grandpa doesn't even k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>They are Queer. I can't believe she's still tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>They are Whites. Oh, you're white, so you prob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>They are Christans. I heard that church is jus...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1008 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence\n",
       "0     They are Asians. I don't want to invite too ma...\n",
       "1     They are Queer. Why do all gay men have to be ...\n",
       "2     They are OldPeople. All Middle Easterners are ...\n",
       "3     They are Females. She's always so put together...\n",
       "4     They are Christans. I don't understand how you...\n",
       "...                                                 ...\n",
       "1003  They are MiddleEastern. I saw a group of Middl...\n",
       "1004  They are Asians. Oh, my grandpa doesn't even k...\n",
       "1005  They are Queer. I can't believe she's still tr...\n",
       "1006  They are Whites. Oh, you're white, so you prob...\n",
       "1007  They are Christans. I heard that church is jus...\n",
       "\n",
       "[1008 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offensivedataset.set_format(type='pandas')\n",
    "compdataset = offensivedataset['train'][1:]\n",
    "compdataset.drop(['category', 'label'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed835e02-5104-4c45-9b6e-291913e0ebc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dbindex(target, comparison):\n",
    "    #Pick a random entry from the comparison dataset.\n",
    "    index = random.randrange(0, len(comparison), 1)\n",
    "\n",
    "    #Find that entry.\n",
    "    comparisonEntry = comparison['sentence'][index]\n",
    "\n",
    "    #Vectoritze entry.\n",
    "    vectorizedComparisonEntry = nlp(comparisonEntry)\n",
    "\n",
    "    #initialitize\u0010 total cosine similarity\n",
    "    tcs = 0\n",
    "\n",
    "    #Go through each target entry\n",
    "    for entry in target.report:\n",
    "        \n",
    "        #Find similariity between each target and the comparison entry\n",
    "        vecEntry = nlp(entry)\n",
    "        tcs += vecEntry.similarity(vectorizedComparisonEntry)\n",
    "\n",
    "    #Raise to inverse power of size\n",
    "    dbi = tcs**(1/len(target))\n",
    "    return dbi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9be16779-2991-4b46-9271-485642a618d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = pd.DataFrame([\"grey\", \"grey\"])\n",
    "target.columns = ['report']\n",
    "comparison = pd.DataFrame(['white', \"red\", \"orange\"])\n",
    "comparison.columns = ['sentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98c18d30-c85d-43ea-ae32-03d852ffa4f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E088] Text of length 1231622 exceeds maximum of 1000000. The parser and NER models require roughly 1GB of temporary memory per 100,000 characters in the input. This means long texts may cause memory allocation errors. If you're not using the parser or NER, it's probably safe to increase the `nlp.max_length` limit. The limit is in number of characters, so you can check whether your inputs are too long by checking `len(text)`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdbindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtargetdset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompdataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 18\u001b[0m, in \u001b[0;36mdbindex\u001b[0;34m(target, comparison)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m#Go through each target entry\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m target\u001b[38;5;241m.\u001b[39mreport:\n\u001b[1;32m     16\u001b[0m     \n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m#Find similariity between each target and the comparison entry\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m     vecEntry \u001b[38;5;241m=\u001b[39m \u001b[43mnlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mentry\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     tcs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m vecEntry\u001b[38;5;241m.\u001b[39msimilarity(vectorizedComparisonEntry)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m#Raise to inverse power of size\u001b[39;00m\n",
      "File \u001b[0;32m~/PycharmProjects/DebiasingLLMS/venv/lib/python3.11/site-packages/spacy/language.py:1030\u001b[0m, in \u001b[0;36mLanguage.__call__\u001b[0;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m   1010\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1011\u001b[0m     text: Union[\u001b[38;5;28mstr\u001b[39m, Doc],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1014\u001b[0m     component_cfg: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, Dict[\u001b[38;5;28mstr\u001b[39m, Any]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1015\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Doc:\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Apply the pipeline to some text. The text can span multiple sentences,\u001b[39;00m\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;124;03m    and can contain arbitrary whitespace. Alignment into the original string\u001b[39;00m\n\u001b[1;32m   1018\u001b[0m \u001b[38;5;124;03m    is preserved.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[38;5;124;03m    DOCS: https://spacy.io/api/language#call\u001b[39;00m\n\u001b[1;32m   1029\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1030\u001b[0m     doc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ensure_doc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1031\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m component_cfg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1032\u001b[0m         component_cfg \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/PycharmProjects/DebiasingLLMS/venv/lib/python3.11/site-packages/spacy/language.py:1121\u001b[0m, in \u001b[0;36mLanguage._ensure_doc\u001b[0;34m(self, doc_like)\u001b[0m\n\u001b[1;32m   1119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m doc_like\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(doc_like, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m-> 1121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_doc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc_like\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(doc_like, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[1;32m   1123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Doc(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab)\u001b[38;5;241m.\u001b[39mfrom_bytes(doc_like)\n",
      "File \u001b[0;32m~/PycharmProjects/DebiasingLLMS/venv/lib/python3.11/site-packages/spacy/language.py:1110\u001b[0m, in \u001b[0;36mLanguage.make_doc\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m   1104\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Turn a text into a Doc object.\u001b[39;00m\n\u001b[1;32m   1105\u001b[0m \n\u001b[1;32m   1106\u001b[0m \u001b[38;5;124;03mtext (str): The text to process.\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;124;03mRETURNS (Doc): The processed doc.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(text) \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_length:\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1111\u001b[0m         Errors\u001b[38;5;241m.\u001b[39mE088\u001b[38;5;241m.\u001b[39mformat(length\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(text), max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_length)\n\u001b[1;32m   1112\u001b[0m     )\n\u001b[1;32m   1113\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer(text)\n",
      "\u001b[0;31mValueError\u001b[0m: [E088] Text of length 1231622 exceeds maximum of 1000000. The parser and NER models require roughly 1GB of temporary memory per 100,000 characters in the input. This means long texts may cause memory allocation errors. If you're not using the parser or NER, it's probably safe to increase the `nlp.max_length` limit. The limit is in number of characters, so you can check whether your inputs are too long by checking `len(text)`."
     ]
    }
   ],
   "source": [
    "dbindex(targetdset, compdataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
