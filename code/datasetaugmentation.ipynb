{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nlpaug.augmenter.char as nac\n",
    "import nlpaug.augmenter.word as naw\n",
    "import nlpaug.augmenter.sentence as nas\n",
    "import nlpaug.flow as nafc\n",
    "import torch\n",
    "import os\n",
    "from datasets import load_dataset \n",
    "from nlpaug.util import Action\n",
    "import spacy \n",
    "from spacy import displacy\n",
    "from langchain.agents import create_pandas_dataframe_agent, load_tools\n",
    "from langchain.llms import OpenAI\n",
    "from getpass import getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c02f411545e016f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "text = \"I think that all African-Americans should deserve jail time.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de6cfb7d-e445-4bb9-8867-10beae1698de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I think that all African-Americans should deserve jail time.\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a4c8fb6-0d92-4699-9da5-e90b8c886f48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['African-Americans']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmentor = naw.AntonymAug()\n",
    "augmentor.augment(text.split(\" \")[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa57e7ce-c92b-4985-aa11-4e87bf10d3a1",
   "metadata": {},
   "source": [
    "Both Synonym and Antonym augmentation do not work very well with race. Use embedding context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4c81ce4-763b-4e34-bc40-6714bd95e882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['African-Americans']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aug = naw.ContextualWordEmbsAug(\n",
    "    model_path='roberta-base', action=\"substitute\")\n",
    "aug.augment(text.split(\" \")[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6410e9d6-94f2-4461-a877-3d4fcb6a05ba",
   "metadata": {},
   "source": [
    "Not very successful; need to do it manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0b9f7651-3933-4c9f-9370-4c04b9fa2daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "OpenAI Key: ········\n"
     ]
    }
   ],
   "source": [
    "os.environ['OPENAI_API_KEY'] = getpass(\"OpenAI Key:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2ea6aa85-dc25-48fd-9812-7e85c3dbd82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = OpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd39e84-a390-4e3c-bb4d-39c82ce6cc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent(\"generate 50 ethnicities and races\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58e7a79f-cb80-4b49-9564-f2d6ccd5d93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_elements = [\n",
    "    \"African\",\n",
    "    \"Afro-Caribbean\",\n",
    "    \"Afro-Latino\",\n",
    "    \"Ainu\",\n",
    "    \"Amazigh\",\n",
    "    \"Ashkenazi Jewish\",\n",
    "    \"Australian Aboriginal\",\n",
    "    \"Basque\",\n",
    "    \"Bantu\",\n",
    "    \"Bengali\",\n",
    "    \"Berber\",\n",
    "    \"Black\",\n",
    "    \"Chinese\",\n",
    "    \"Cree\",\n",
    "    \"Cuban\",\n",
    "    \"Druze\",\n",
    "    \"Dutch\",\n",
    "    \"English\",\n",
    "    \"Filipino\",\n",
    "    \"Finnish\",\n",
    "    \"French\",\n",
    "    \"Gaelic\",\n",
    "    \"German\",\n",
    "    \"Greek\",\n",
    "    \"Guatemalan\",\n",
    "    \"Han Chinese\",\n",
    "    \"Hausa\",\n",
    "    \"Hawaiian\",\n",
    "    \"Hispanic/Latino\",\n",
    "    \"Hmong\",\n",
    "    \"Hopi\",\n",
    "    \"Inuit\",\n",
    "    \"Italian\",\n",
    "    \"Japanese\",\n",
    "    \"Jewish\",\n",
    "    \"Karen\",\n",
    "    \"Khmer\",\n",
    "    \"Korean\",\n",
    "    \"Maori\",\n",
    "    \"Maya\",\n",
    "    \"Mongolian\",\n",
    "    \"Native American\",\n",
    "    \"Nigerian\",\n",
    "    \"Nubian\",\n",
    "    \"Pashtun\",\n",
    "    \"Persian\",\n",
    "    \"Quechua\",\n",
    "    \"Romani\",\n",
    "    \"Sami\",\n",
    "    \"Somali\",\n",
    "    \"Tajik\",\n",
    "    \"Tamil\",\n",
    "    \"Tatar\",\n",
    "    \"Thai\",\n",
    "    \"Tibetan\",\n",
    "    \"Tuareg\",\n",
    "    \"Turkish\",\n",
    "    \"Uighur\",\n",
    "    \"Ukrainian\",\n",
    "    \"Vietnamese\",\n",
    "    \"Yakut\",\n",
    "    \"Yoruba\",\n",
    "    \"Zulu\",\n",
    "    \"Albanian\",\n",
    "    \"Arab\",\n",
    "    \"Armenian\",\n",
    "    \"Assyrian\",\n",
    "    \"Aymara\",\n",
    "    \"Balinese\",\n",
    "    \"Bashkir\",\n",
    "    \"Belizean\",\n",
    "    \"Bolivian\",\n",
    "    \"Bosniak\",\n",
    "    \"Bulgarian\",\n",
    "    \"Cambodian\",\n",
    "    \"Cameroonian\",\n",
    "    \"Catalan\",\n",
    "    \"Chamorro\",\n",
    "    \"Chechen\",\n",
    "    \"Cherokee\",\n",
    "    \"Chuvash\",\n",
    "    \"Coptic\",\n",
    "    \"Corsican\",\n",
    "    \"Crimean Tatar\",\n",
    "    \"Croatian\",\n",
    "    \"Czech\",\n",
    "    \"Danish\",\n",
    "    \"Dinka\",\n",
    "    \"Ecuadorian\",\n",
    "    \"Estonian\",\n",
    "    \"Ethiopian\",\n",
    "    \"Fijian\",\n",
    "    \"Georgian\",\n",
    "    \"Gujarati\",\n",
    "    \"Haitian\",\n",
    "    \"Hazaras\",\n",
    "    \"Ibo\",\n",
    "    \"Icelandic\",\n",
    "    \"Indigenous Australian\",\n",
    "    \"Indigenous Malaysian\",\n",
    "    \"Iraqi\",\n",
    "    \"Iroquois\",\n",
    "    \"Kurdish\",\n",
    "    \"Latvian\",\n",
    "    \"Lebanese\",\n",
    "    \"Lithuanian\",\n",
    "    \"Macedonian\",\n",
    "    \"Malay\",\n",
    "    \"Maldivian\",\n",
    "    \"Maltese\",\n",
    "    \"Maasai\",\n",
    "    \"Mende\",\n",
    "    \"Mien\",\n",
    "    \"Mizrahi Jewish\",\n",
    "    \"Monguor\",\n",
    "    \"Moroccan\",\n",
    "    \"Navajo\",\n",
    "    \"Nenets\",\n",
    "    \"Nepali\",\n",
    "    \"Norwegian\",\n",
    "    \"Pakistani\",\n",
    "    \"Palestinian\",\n",
    "    \"Papua New Guinean\",\n",
    "    \"Parsi\",\n",
    "    \"Peruvian\",\n",
    "    \"Polish\",\n",
    "    \"Portuguese\",\n",
    "    \"Punjabi\",\n",
    "    \"Roma\",\n",
    "    \"Samoan\",\n",
    "    \"Scots\",\n",
    "    \"Sindhi\",\n",
    "    \"Slovak\",\n",
    "    \"Slovene\",\n",
    "    \"Sorbian\",\n",
    "    \"Sudanese\",\n",
    "    \"Swedish\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "339fe6f6-ec83-48e0-863a-111993bcf053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['report', 'summary'],\n",
       "        num_rows: 17517\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['report', 'summary'],\n",
       "        num_rows: 973\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['report', 'summary'],\n",
       "        num_rows: 973\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_dataset = load_dataset(\"ccdv/govreport-summarization\")\n",
    "base_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddcd03e-b8eb-45b9-9024-b38aad5985dc",
   "metadata": {},
   "source": [
    "Procedure:\n",
    "- Iterate through each data entry, and do spaCy named entity recognition for race.\n",
    "- Once found, take entry, and copy in word from list of bias elements to generate new entry.\n",
    "- Each entry will then be augmented in size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0fabfea-46c4-4b89-a526-0c17dfed026c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0abb7f56-9a5a-4ae2-8a67-d97d84b95e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg = ner(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8bdcf37c-c93e-43d8-b060-836409453a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "African-Americans NORP\n"
     ]
    }
   ],
   "source": [
    "for word in seg.ents:\n",
    "    print(word.text, word.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba9eac07-6576-403e-b397-4ee3705d51ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nationalities or religious or political groups'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain(\"NORP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1b4b66d1-a21d-4631-8354-c4eaa0cb0098",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dataset.set_format(type='pandas')\n",
    "\n",
    "df = base_dataset['train'][:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "61f29030-e602-458a-8fea-a13b84980798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The structure of the armed forces is based on ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              report\n",
       "0  The structure of the armed forces is based on ..."
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['summary'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0bd8d4a2-f6c0-40c8-b5fa-8716222e7415",
   "metadata": {},
   "outputs": [],
   "source": [
    "def raceDetection():\n",
    "\n",
    "    numberOfEthnicities = 0\n",
    "\n",
    "    for entry in df.report:\n",
    "    \n",
    "        seg = ner(entry)\n",
    "    \n",
    "        for word in seg.ents:\n",
    "            if word.label_ == \"NORP\":\n",
    "                numberOfEthnicities += 1\n",
    "\n",
    "\n",
    "    return numberOfEthnicities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f720ebc1-efe3-488a-a120-9c56ff5b42e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def datasetAugmentation():\n",
    "\n",
    "    #Initialize summarizer\n",
    "    sum = nas.AbstSummAug()\n",
    "\n",
    "    #Initialize sentence augmentation\n",
    "    aug = nas.ContextualWordEmbsForSentenceAug(model_path='xlnet-base-cased')\n",
    "    \n",
    "    #Iterate throguh each entry.\n",
    "    for entry in df.report:\n",
    "\n",
    "        #for each entry do Named Entity Recognition on each word\n",
    "        seg = ner(entry)\n",
    "\n",
    "        #find if any of the words pertain to a race\n",
    "        for word in seg.ents:\n",
    "            if word.label_ == \"NORP\":\n",
    "\n",
    "                #if a word pertains to race, substitute in each entry of the bias elements\n",
    "                for race in bias_elements:\n",
    "                    newEntry = entry.replace(word.text, race)\n",
    "                    df.loc[len(df.index)] = newEntry\n",
    "\n",
    "                    #Do content downshift through summarization of new entry (abstractive summarization), and add\n",
    "                    newEntrySum = sum.augment(newEntry)\n",
    "                    df.loc[len(df.index)] = newEntrySum\n",
    "\n",
    "                    #Do vocabulary upshift through augmentation, and add \n",
    "                    newEntryComp = aug.augment(newEntry)\n",
    "                    df.loc[len(df.index)] = newEntryComp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80899e7d-0700-43f4-b0d3-944ba532c317",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (11787 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "datasetAugmentation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78e662d-ebe0-4e8f-be51-c740aa573e24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
